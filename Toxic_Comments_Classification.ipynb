{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_8UbV_19Uq7",
    "outputId": "34e488d7-f49e-4ec1-8d2a-c958fcbf05c5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # Import the pandas library for data manipulation and analysis\n",
    "\n",
    "# Load the training dataset\n",
    "# This dataset contains the comments and their corresponding labels for training the model\n",
    "train = pd.read_csv('./train.csv')\n",
    "\n",
    "# Load the test dataset\n",
    "test = pd.read_csv('./test.csv')\n",
    "\n",
    "# Load the sample submission file\n",
    "sample = pd.read_csv('./sample_submission.csv')\n",
    "\n",
    "# Print a confirmation message to indicate successful loading of the datasets\n",
    "print(\"Datasets loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "JOweIXOL9UrP"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykiMfTki9jML",
    "outputId": "dcf07901-3337-4fa8-b36e-34659bada3f6"
   },
   "outputs": [],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5ixc54GAV_j",
    "outputId": "2de24128-eb28-47b3-9b36-39541c09a1af"
   },
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7wSl0CG9UrX",
    "outputId": "47f1a83e-4c82-4b80-96a6-3202869c8b04"
   },
   "outputs": [],
   "source": [
    "## Data Collection and Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## Data Preprocessing\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# UnderSampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "\n",
    "## Model Creation\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, SpatialDropout1D, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "Vy6UxKwt9Urd"
   },
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NlhDT2VJ9Urg",
    "outputId": "e6102f8d-69e8-44cd-fb65-7756252e5312"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Hy1gYuwe9Urj",
    "outputId": "318dcf38-3c2d-43a0-eea6-12dd26e70446"
   },
   "outputs": [],
   "source": [
    "train.drop(\"id\", axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "D9DsTV3l9Urm",
    "outputId": "e21722e7-6098-45a5-8627-dd6ec49b4fe0"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WDM4SUbD9Urp",
    "outputId": "9846c79c-2de9-4c29-c5ed-94ad48bf54e7"
   },
   "outputs": [],
   "source": [
    "test_y = pd.read_csv(\"./test_labels.csv\")\n",
    "test_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SJ7stgt59Uru",
    "outputId": "a2d3fd89-a69d-4f63-d109-24d9d1938e72"
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, test_y, on = \"id\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oS0Hy1O59Urw",
    "outputId": "2d962394-345e-4a06-c96a-14cfc43ae895"
   },
   "outputs": [],
   "source": [
    "test = test.drop(test[test[\"toxic\"] == -1].index)\n",
    "test.drop(\"id\", axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpoOcIaVgu_W",
    "outputId": "8a855991-6b2b-4b0e-ec9c-302d74589158"
   },
   "outputs": [],
   "source": [
    "target_columns = list(sample.columns.drop('id'))\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "hdwOs2ERgvDY",
    "outputId": "00118bba-3151-492b-e118-50edf3065469"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "x3Jvw3-z9Urz",
    "outputId": "505145e7-decb-41dd-b1e0-2e94086ae0e8"
   },
   "outputs": [],
   "source": [
    "train[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "mN201fOH9Ur1",
    "outputId": "004c54b9-4e94-4e8e-e3ca-3340c83838d5"
   },
   "outputs": [],
   "source": [
    "test[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "id": "0O_hLAT7g0cr",
    "outputId": "c7d755ff-9ee9-4599-dc17-a6b4b0a68ba5"
   },
   "outputs": [],
   "source": [
    "# The counts show an imbalanced dataset, both between labels but also with no label at all:\n",
    "train[target_columns].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "lvh_qfBd9Ur2"
   },
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "T9QXeVhR9Ur3",
    "outputId": "b0db4231-3a0d-4b4a-c915-a0d6831311dd"
   },
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)\n",
    "comment_len = train.comment_text.str.len()\n",
    "sns.distplot(comment_len, kde=False, bins=20, color=\"steelblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "gykJQvqn9Ur4"
   },
   "outputs": [],
   "source": [
    "train_labels = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]\n",
    "label_count = train_labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "uNyUinDH9Ur6",
    "outputId": "a8b72848-f430-4c7c-ba3a-80f8203e1fc2"
   },
   "outputs": [],
   "source": [
    "label_count.plot(kind='bar', title='Labels Frequency', color='steelblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "HCzJkizT9Ur7",
    "outputId": "90275e5b-37b5-43eb-be59-5268298eb131"
   },
   "outputs": [],
   "source": [
    "barWidth = 0.25  # Width of bars in the chart\n",
    "\n",
    "# Counts of positive (1) and negative (0) labels for each category\n",
    "bars1 = [sum(train['toxic'] == 1), sum(train['obscene'] == 1), sum(train['insult'] == 1),\n",
    "         sum(train['severe_toxic'] == 1), sum(train['identity_hate'] == 1), sum(train['threat'] == 1)]\n",
    "bars2 = [sum(train['toxic'] == 0), sum(train['obscene'] == 0), sum(train['insult'] == 0),\n",
    "         sum(train['severe_toxic'] == 0), sum(train['identity_hate'] == 0), sum(train['threat'] == 0)]\n",
    "\n",
    "# Positions for bars\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.bar(r1, bars1, color='steelblue', width=barWidth, label='labeled = 1')\n",
    "plt.bar(r2, bars2, color='lightsteelblue', width=barWidth, label='labeled = 0')\n",
    "\n",
    "# Adding labels and showing the chart\n",
    "plt.xlabel('group', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))],\n",
    "           ['Toxic', 'Obscene', 'Insult', 'Severe Toxic', 'Identity Hate', 'Threat'])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "id": "XLRMkmvH9Ur8",
    "outputId": "cf4c373c-4591-4ea9-b4ec-f16039ba7613"
   },
   "outputs": [],
   "source": [
    "# Calculate the sum of all label values for each row\n",
    "rowsums = train.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "# Filter the dataset for rows with at least one positive label\n",
    "temp = train.iloc[:, 2:-1]\n",
    "train_corr = temp[rowsums > 0]\n",
    "\n",
    "# Compute correlation between labels\n",
    "corr = train_corr.corr()\n",
    "\n",
    "# Plot the heatmap of label correlations\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values, annot=True, cmap=\"Blues\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "OyPzXCX19UsG"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "ub_Y2XMn9UsI",
    "outputId": "7ddc3cc3-f9af-4ca6-9c3e-8878be3cf884"
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "ZnRPQMLn9UsI",
    "outputId": "573ba8d5-b30b-4e83-fea6-d0fe54f8ac7e"
   },
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DRoRE7W9UsK",
    "outputId": "935f4f4e-8370-4c74-eaaa-11644d2ad4f0"
   },
   "outputs": [],
   "source": [
    "# Download necessary NLTK resource for lemmatization\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define a text preprocessing function\n",
    "def preprocess_text(text, remove_repeat_text=True, remove_patterns_text=True, is_lower=True):\n",
    "    # Convert text to lowercase\n",
    "    if is_lower:\n",
    "        text = text.lower()\n",
    "\n",
    "    # Remove repeated characters (e.g., \"heeeello\" -> \"helo\")\n",
    "    if remove_repeat_text:\n",
    "        text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
    "\n",
    "    # If input is a list, join into a single string\n",
    "    if isinstance(text, list):\n",
    "        text = ' '.join(text)\n",
    "\n",
    "    # Replace newline characters with spaces\n",
    "    text = str(text).replace(\"\\n\", \" \")\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    # Remove numeric characters\n",
    "    text = re.sub('[0-9]', \"\", text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(\" +\", \" \", text)\n",
    "\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(\"([^\\x00-\\x7F])+\", \" \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to train and test datasets\n",
    "train[\"cleaned_comments\"] = train[\"comment_text\"].apply(preprocess_text)\n",
    "test[\"cleaned_comments\"] = test[\"comment_text\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "5_MtR3J0wpzj",
    "outputId": "f67da616-007b-4f84-853e-f0b7ebf348bc"
   },
   "outputs": [],
   "source": [
    "train[\"cleaned_comments\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "G2dumYQbwzBF",
    "outputId": "50ec9517-ff65-4418-c941-b117712bb69d"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XlQS-vkD9UsM",
    "outputId": "fb34562e-9f92-4516-8029-b428094117d1"
   },
   "outputs": [],
   "source": [
    "def generate_wordcloud(data, label):\n",
    "    text = ' '.join(data[data['toxic'] == label]['cleaned_comments'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='black').generate(text)\n",
    "    return wordcloud\n",
    "\n",
    "# Training data word clouds\n",
    "train_toxic_wordcloud = generate_wordcloud(train, 1)\n",
    "train_nontoxic_wordcloud = generate_wordcloud(train, 0)\n",
    "\n",
    "# Test data word clouds\n",
    "test_toxic_wordcloud = generate_wordcloud(test, 1)\n",
    "test_nontoxic_wordcloud = generate_wordcloud(test, 0)\n",
    "\n",
    "# Plot the word clouds\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.imshow(train_toxic_wordcloud.recolor(colormap=\"Blues\"), interpolation='bilinear')\n",
    "plt.title('Toxic Comments - Training Data', size=20)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(train_nontoxic_wordcloud.recolor(colormap=\"Blues\"), interpolation='bilinear')\n",
    "plt.title('Non-Toxic Comments - Training Data', size=20)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(test_toxic_wordcloud.recolor(colormap=\"Blues\"), interpolation='bilinear')\n",
    "plt.title('Toxic Comments - Test Data', size=20)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.imshow(test_nontoxic_wordcloud.recolor(colormap=\"Blues\"), interpolation='bilinear')\n",
    "plt.title('Non-Toxic Comments - Test Data', size=20)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3cnlgFBwzpX",
    "outputId": "e544bc06-8c90-4320-c92f-4d1a3c769e02"
   },
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download('omw-1.4')       # Download WordNet for lemmatization\n",
    "nltk.download('punkt_tab')     # Download tokenizer resources\n",
    "nltk.download('stopwords')     # Download list of stopwords\n",
    "nltk.download('wordnet')       # Download WordNet lexical database\n",
    "\n",
    "# Define stop words and lemmatizer for preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words and convert to lowercase\n",
    "    filtered_tokens = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Lemmatize the tokens to their base form\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    preprocessed_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "# Apply the preprocessing function to train and test datasets\n",
    "train['comment_text'] = train['cleaned_comments'].apply(preprocess_text)\n",
    "test['comment_text'] = test['cleaned_comments'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "yYLGOCoz9UsM",
    "outputId": "66bd8fb2-2457-427c-d339-d2c5d51e7b4e"
   },
   "outputs": [],
   "source": [
    "train[\"cleaned_comments\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "18HB4rRzyxXi",
    "outputId": "395a80a7-f219-461a-d6d6-59ec00ca5730"
   },
   "outputs": [],
   "source": [
    "train[\"comment_text\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {
    "id": "_8vS0qA-ApEf"
   },
   "source": [
    "# UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "id": "r-SdT-56_ihW"
   },
   "outputs": [],
   "source": [
    "X_train = train[\"comment_text\"].values\n",
    "y_train = np.array(train[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "id": "eqQbrGJaA8ji"
   },
   "outputs": [],
   "source": [
    "X_test = test[\"comment_text\"].values\n",
    "y_test = np.array(test[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qQnkPqG_CASB",
    "outputId": "c52e4375-c5b8-4ea9-9221-4a9eae46ce0d"
   },
   "outputs": [],
   "source": [
    "print(\"Original training data distribution:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MolI_txB4rp",
    "outputId": "c5941e52-93ba-40f7-c22e-5db23e002f69"
   },
   "outputs": [],
   "source": [
    "print(\"Original testing data distribution:\", Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "id": "sF3_DymHBLQz"
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "id": "7GnU3Jp4BPdu"
   },
   "outputs": [],
   "source": [
    "X_resampled_train, y_resampled_train = rus.fit_resample(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MJ1OL-z8Bsso",
    "outputId": "c43a3a60-43b0-4f3d-9620-886a6b96c9f0"
   },
   "outputs": [],
   "source": [
    "print(\"Sampling training data distribution:\", Counter(y_resampled_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "id": "LBdvmeuVCWML"
   },
   "outputs": [],
   "source": [
    "X_resampled_test, y_resampled_test = rus.fit_resample(X_test.reshape(-1, 1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYbWcwrsCtA4",
    "outputId": "c2cc6539-0592-46f7-d126-9e5d708a1d22"
   },
   "outputs": [],
   "source": [
    "print(\"Sampling testing data distribution:\", Counter(y_resampled_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "id": "BM5EieOLDLCx"
   },
   "outputs": [],
   "source": [
    "X_resampled_train = pd.DataFrame(X_resampled_train, columns=[\"comment_text\"])\n",
    "y_resampled_train = pd.Series(y_resampled_train, name=\"toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "id": "mtMGkS56Fs40"
   },
   "outputs": [],
   "source": [
    "X_resampled_test = pd.DataFrame(X_resampled_test, columns=[\"comment_text\"])\n",
    "y_resampled_test = pd.Series(y_resampled_test, name=\"toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "id": "A9WqZJx7EqAL"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "pSCjgCAtEaS7",
    "outputId": "f9ba4522-dd23-4e62-8dab-23f57298f8e4"
   },
   "outputs": [],
   "source": [
    "y_resampled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "29tGzX-YzPQZ",
    "outputId": "52f3945d-685f-4bfb-ef15-5a16d3334d95"
   },
   "outputs": [],
   "source": [
    "X_resampled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "id": "Hahq9knAJnhl"
   },
   "outputs": [],
   "source": [
    "X_train_resampled, X_val_resampled, y_train_resampled, y_val_resampled = train_test_split(\n",
    "    X_resampled_train[\"comment_text\"],\n",
    "    y_resampled_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "qGQHLf7S326E",
    "outputId": "4a0a5047-cc3e-45fd-c460-eeb82c5613c5"
   },
   "outputs": [],
   "source": [
    "X_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "KACMJnnp5kZy",
    "outputId": "30928f42-564b-48d7-b26f-ed20628aecb9"
   },
   "outputs": [],
   "source": [
    "X_val_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "gqCRp6G45muI",
    "outputId": "01b06e6f-2f09-4675-a1e0-3ad304db4dec"
   },
   "outputs": [],
   "source": [
    "X_resampled_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "KRRWp-S69UsN"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBVID1FFzyTj",
    "outputId": "d559fa9e-dc2d-4e92-937c-969361c6a4c8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import KFold  # For K-fold cross-validation\n",
    "from sklearn.metrics import roc_auc_score, classification_report  # Evaluation metrics\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset  # PyTorch utilities for data handling\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW  # Hugging Face's BERT and optimization tools\n",
    "\n",
    "# Parameters\n",
    "target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']  # Labels for multi-label classification\n",
    "k_folds = 5  # Number of folds for cross-validation\n",
    "batch_size = 16  # Batch size for data loading\n",
    "epochs = 5  # Number of training epochs\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to encode textual data into token IDs and attention masks for BERT\n",
    "def encode(data, tokenizer, max_length=150):\n",
    "    encoded_data = tokenizer.batch_encode_plus(\n",
    "        data.tolist(),  # Input text\n",
    "        max_length=max_length,  # Maximum token length for padding/truncation\n",
    "        padding='max_length',  # Pad sequences to the maximum length\n",
    "        truncation=True,  # Truncate sequences longer than max_length\n",
    "        return_tensors='pt'  # Return data as PyTorch tensors\n",
    "    )\n",
    "    return encoded_data['input_ids'], encoded_data['attention_mask']  # Return input IDs and attention masks\n",
    "\n",
    "# Prepare the training and test data\n",
    "X = train['cleaned_comments'].values  # Input text for training\n",
    "y = train[target_columns].values  # Target labels for training\n",
    "X_test = test['cleaned_comments'].values  # Input text for testing\n",
    "y_test = test[target_columns].values  # Target labels for testing\n",
    "\n",
    "# Encode test data using BERT tokenizer\n",
    "X_test_input_ids, X_test_attention_masks = encode(pd.Series(X_test), tokenizer)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)  # Convert test labels to PyTorch tensor\n",
    "\n",
    "# Create a DataLoader for the test data\n",
    "test_data = TensorDataset(X_test_input_ids, X_test_attention_masks, y_test_tensor)  # Create a dataset\n",
    "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)  # Use sequential sampling\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)  # Initialize KFold with shuffling and a fixed random state\n",
    "\n",
    "fold_results = []  # Store results for each fold\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    print(f\"\\n--- Fold {fold + 1}/{k_folds} ---\")\n",
    "\n",
    "    # Split data into training and validation sets for this fold\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]  # Training and validation inputs\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]  # Training and validation labels\n",
    "\n",
    "    # Encode training and validation data using the tokenizer\n",
    "    X_train_input_ids, X_train_attention_masks = encode(pd.Series(X_train_fold), tokenizer)\n",
    "    X_val_input_ids, X_val_attention_masks = encode(pd.Series(X_val_fold), tokenizer)\n",
    "\n",
    "    # Convert training and validation labels to PyTorch tensors\n",
    "    y_train_tensor = torch.tensor(y_train_fold, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val_fold, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {
    "id": "MHUNMQSrJ9F9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "\n",
    "# Batch size for data loading\n",
    "batch_size = 16\n",
    "\n",
    "# Create DataLoader for training data\n",
    "# RandomSampler ensures random shuffling of data during each epoch\n",
    "train_data = TensorDataset(X_train_input_ids, X_train_attention_masks, y_train_tensor)  # Create dataset\n",
    "train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)  # DataLoader for training\n",
    "\n",
    "# Create DataLoader for validation data\n",
    "# SequentialSampler ensures the validation data is processed in order\n",
    "val_data = TensorDataset(X_val_input_ids, X_val_attention_masks, y_val_tensor)  # Create dataset\n",
    "val_dataloader = DataLoader(val_data, sampler=SequentialSampler(val_data), batch_size=batch_size)  # DataLoader for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "id": "a9nXa4zONmnN"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from transformers import EarlyStoppingCallback\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364,
     "referenced_widgets": [
      "a44c6fc5a2154191b1a527cf6fe7b87e",
      "15031abaec2c478f9c3450a75bd1f059",
      "7ff2e0309f2e4c96a17d895d2f313876",
      "17e7a827bf7c4871bbf6111733a82f5d",
      "bdcb3a28a525439fa74a53bf403385ac",
      "597a929b7a2e4b9b90f7fe3687ef778a",
      "131c6a558fae42f38028bdfe1b0c4bce",
      "d0852e8d29c74a37a9a2ae017ea67ad9",
      "908e8b9fff014256b70ed78e2dcafe31",
      "984c0a45ee2a4b69aa64265f1108272f",
      "f72b326653af41ce99bc95557eefb0ba"
     ]
    },
    "id": "9VMohlc0J9Pd",
    "outputId": "5dc03161-0a2c-4b5c-dda8-45a76ee7c178"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "# Initialize the BERT model for multi-label classification with pre-trained weights\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(target_columns))\n",
    "model = model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))  # Move model to GPU if available\n",
    "\n",
    "# Define optimizer\n",
    "# AdamW optimizer for fine-tuning with weight decay\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')  # Track the best validation loss for model selection\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0  # Initialize total loss for the epoch\n",
    "\n",
    "    # Train phase\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Move inputs and labels to the device (GPU or CPU)\n",
    "        batch_input_ids, batch_attention_mask, batch_labels = tuple(t.to(model.device) for t in batch)\n",
    "        model.zero_grad()  # Reset gradients\n",
    "        outputs = model(batch_input_ids, attention_mask=batch_attention_mask, labels=batch_labels)  # Forward pass\n",
    "        loss = outputs.loss  # Compute loss\n",
    "        total_loss += loss.item()  # Accumulate loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "    # Compute and display average training loss for the epoch\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35nDukjQtj4Z",
    "outputId": "e64a2d20-0970-4260-fca1-f0bb25971f4a"
   },
   "outputs": [],
   "source": [
    "# Validation phase\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "val_loss = 0  # Initialize validation loss\n",
    "val_preds, val_labels = [], []  # Store predictions and true labels for evaluation\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for validation\n",
    "    for batch in val_dataloader:\n",
    "        # Move inputs and labels to the device (GPU or CPU)\n",
    "        batch_input_ids, batch_attention_mask, batch_labels = tuple(t.to(model.device) for t in batch)\n",
    "\n",
    "        # Forward pass to get predictions and loss\n",
    "        outputs = model(batch_input_ids, attention_mask=batch_attention_mask, labels=batch_labels)\n",
    "        val_loss += outputs.loss.item()  # Accumulate validation loss\n",
    "\n",
    "        # Store predictions and labels for metrics calculation\n",
    "        val_preds.append(torch.sigmoid(outputs.logits).cpu().numpy())  # Convert logits to probabilities\n",
    "        val_labels.append(batch_labels.cpu().numpy())\n",
    "\n",
    "# Compute average validation loss\n",
    "avg_val_loss = val_loss / len(val_dataloader)\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Save the best model for this fold if validation loss improves\n",
    "if avg_val_loss < best_val_loss:\n",
    "    best_val_loss = avg_val_loss  # Update the best validation loss\n",
    "    torch.save(model.state_dict(), f\"best_model_fold_{fold}.pth\")  # Save the model's state dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "li18sSVfuzHe",
    "outputId": "d4458e1b-ec58-4d9a-aa91-35f2cbf02f31"
   },
   "outputs": [],
   "source": [
    "# Evaluate validation set\n",
    "val_preds = np.vstack(val_preds)  # Stack validation predictions vertically\n",
    "val_labels = np.vstack(val_labels)  # Stack validation true labels vertically\n",
    "fold_val_auc = roc_auc_score(val_labels, val_preds, average='macro')  # Compute macro-average AUC for validation\n",
    "print(f\"Fold {fold + 1} Validation AUC: {fold_val_auc:.4f}\")\n",
    "\n",
    "# Load the best model for this fold and evaluate it on the test set\n",
    "model.load_state_dict(torch.load(f\"best_model_fold_{fold}.pth\"))  # Load the saved best model for this fold\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_preds, test_labels = [], []  # Initialize lists to store test predictions and true labels\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation during test evaluation\n",
    "    for batch in test_dataloader:\n",
    "        # Move inputs and labels to the device (GPU or CPU)\n",
    "        batch_input_ids, batch_attention_mask, batch_labels = tuple(t.to(model.device) for t in batch)\n",
    "\n",
    "        # Forward pass to get predictions\n",
    "        outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        test_preds.append(torch.sigmoid(outputs.logits).cpu().numpy())  # Convert logits to probabilities\n",
    "        test_labels.append(batch_labels.cpu().numpy())  # Store true labels\n",
    "\n",
    "# Stack predictions and labels for test evaluation\n",
    "test_preds = np.vstack(test_preds)\n",
    "test_labels = np.vstack(test_labels)\n",
    "\n",
    "# Compute macro-average AUC for the test set\n",
    "fold_test_auc = roc_auc_score(test_labels, test_preds, average='macro')\n",
    "print(f\"Fold {fold + 1} Test AUC: {fold_test_auc:.4f}\")\n",
    "\n",
    "# Append the fold's validation and test AUC scores to the results list\n",
    "fold_results.append((fold_val_auc, fold_test_auc))\n",
    "\n",
    "# Compute overall validation and test results across all folds\n",
    "val_aucs = [result[0] for result in fold_results]  # Extract validation AUCs\n",
    "test_aucs = [result[1] for result in fold_results]  # Extract test AUCs\n",
    "print(f\"\\nOverall Validation AUC: {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}\")  # Average and std for validation AUCs\n",
    "print(f\"Overall Test AUC: {np.mean(test_aucs):.4f} ± {np.std(test_aucs):.4f}\")  # Average and std for test AUCs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zw_h-yLyP5to",
    "outputId": "e81474f4-2a55-43cb-94e2-0c44dac19a1d"
   },
   "outputs": [],
   "source": [
    "# Multi-label classification report and metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "\n",
    "# Define target column names (multi-label classification)\n",
    "target_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_preds, test_labels = [], []  # Initialize lists for predictions and true labels\n",
    "with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "    for batch in test_dataloader:\n",
    "        batch_input_ids, batch_attention_mask, batch_labels = tuple(t.to(model.device) for t in batch)\n",
    "        outputs = model(batch_input_ids, attention_mask=batch_attention_mask)  # Forward pass\n",
    "        logits = outputs.logits  # Raw logits from the model\n",
    "        test_preds.append(torch.sigmoid(logits).cpu().numpy())  # Convert logits to probabilities\n",
    "        test_labels.append(batch_labels.cpu().numpy())  # Store true labels\n",
    "\n",
    "# Convert predictions and labels to arrays for metrics calculation\n",
    "test_preds = np.vstack(test_preds)\n",
    "test_labels = np.vstack(test_labels)\n",
    "\n",
    "# Initialize macro-average AUC and thresholds for optimal F1\n",
    "macro_auc = 0\n",
    "optimal_thresholds = []  # Store the best threshold for each label\n",
    "\n",
    "print(\"\\nClassification Reports for Each Label:\")\n",
    "for i, label in enumerate(target_columns):\n",
    "    print(f\"\\nLabel: {label}\")\n",
    "    true_labels = test_labels[:, i]  # True labels for the current label\n",
    "    predicted_probs = test_preds[:, i]  # Predicted probabilities for the current label\n",
    "\n",
    "    # Determine optimal threshold using the precision-recall curve\n",
    "    precision, recall, thresholds = precision_recall_curve(true_labels, predicted_probs)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)  # Compute F1 scores\n",
    "    optimal_idx = f1_scores.argmax()  # Index of the maximum F1 score\n",
    "    optimal_threshold = thresholds[optimal_idx] if len(thresholds) > 0 else 0.5  # Set threshold\n",
    "    optimal_thresholds.append(optimal_threshold)\n",
    "\n",
    "    # Predict labels using the optimal threshold\n",
    "    predicted_labels = (predicted_probs > optimal_threshold).astype(int)\n",
    "\n",
    "    # Generate and display the classification report\n",
    "    print(classification_report(true_labels, predicted_labels, target_names=[f\"Non-{label}\", label]))\n",
    "\n",
    "    # Calculate the AUC score for the current label\n",
    "    auc = roc_auc_score(true_labels, predicted_probs)\n",
    "    print(f\"AUC: {auc:.4f}\")\n",
    "    print(f\"Optimal Threshold for {label}: {optimal_threshold:.2f}\")\n",
    "    macro_auc += auc  # Accumulate macro AUC\n",
    "\n",
    "# Calculate Macro-Average AUC across all labels\n",
    "macro_auc /= len(target_columns)\n",
    "\n",
    "# Calculate overall metrics using optimized thresholds\n",
    "predicted_labels = np.zeros_like(test_preds)  # Initialize predictions\n",
    "for i in range(test_preds.shape[1]):\n",
    "    predicted_labels[:, i] = (test_preds[:, i] > optimal_thresholds[i]).astype(int)  # Apply optimal thresholds\n",
    "\n",
    "# Flatten predictions and true labels for overall metrics calculation\n",
    "accuracy = accuracy_score(test_labels.flatten(), predicted_labels.flatten())\n",
    "precision = precision_score(test_labels, predicted_labels, average='macro')\n",
    "recall = recall_score(test_labels, predicted_labels, average='macro')\n",
    "f1 = f1_score(test_labels, predicted_labels, average='macro')\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"\\nOverall Metrics (Using Tuned Thresholds):\")\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro Average AUC: {macro_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KceS5DaKN5CM",
    "outputId": "24e72068-2314-4b40-d3fd-cb69d01c3841"
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "torch.save(model.state_dict(), \"bert_toxicity_model.pth\")\n",
    "tokenizer.save_pretrained('./bert_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yg6_-LEdJ9aG",
    "outputId": "9f533a6a-c18e-4b25-eea3-eecba3737c1e"
   },
   "outputs": [],
   "source": [
    "def predict_toxicity(text, model, tokenizer, target_columns, optimal_thresholds, max_length=150):\n",
    "    \"\"\"\n",
    "    Predict whether a given text is toxic or non-toxic using a fine-tuned BERT model.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to be classified.\n",
    "        model: Fine-tuned BERT model.\n",
    "        tokenizer: Tokenizer used for the BERT model.\n",
    "        target_columns (list): List of target labels.\n",
    "        optimal_thresholds (list): Thresholds tuned for each label.\n",
    "        max_length (int): Maximum token length for BERT input.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the toxicity classification for each label.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize and preprocess the input text\n",
    "    encoded_input = tokenizer(\n",
    "        text,                     # Input text to be tokenized\n",
    "        max_length=max_length,    # Truncate or pad to this length\n",
    "        padding=\"max_length\",     # Add padding if text length is less than max_length\n",
    "        truncation=True,          # Truncate text if it exceeds max_length\n",
    "        return_tensors=\"pt\"       # Return data as PyTorch tensors\n",
    "    )\n",
    "    input_ids = encoded_input['input_ids'].to(model.device)  # Move input IDs to the model's device\n",
    "    attention_mask = encoded_input['attention_mask'].to(model.device)  # Move attention mask to the model's device\n",
    "\n",
    "    # Perform forward pass to get predictions\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)  # Get model outputs\n",
    "        logits = outputs.logits  # Extract logits\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]  # Apply sigmoid to get probabilities\n",
    "\n",
    "    # Determine if each label is toxic based on optimal thresholds\n",
    "    prediction = {}\n",
    "    for i, label in enumerate(target_columns):  # Iterate through each label\n",
    "        is_toxic = probabilities[i] > optimal_thresholds[i]  # Compare probability with the threshold\n",
    "        prediction[label] = \"Toxic\" if is_toxic else \"Non-Toxic\"  # Assign \"Toxic\" or \"Non-Toxic\"\n",
    "\n",
    "    return prediction  # Return the predictions as a dictionary\n",
    "\n",
    "# Example Usage\n",
    "text = \"You are an asshole!\"\n",
    "predictions = predict_toxicity(text, model, tokenizer, target_columns, optimal_thresholds)\n",
    "print(f\"Predictions for '{text}':\")\n",
    "for label, result in predictions.items():\n",
    "    print(f\"{label}: {result}\")  # Print predictions for each label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-eaZvulWqQC",
    "outputId": "8fa65090-c79a-490d-a50b-3e814be96a13"
   },
   "outputs": [],
   "source": [
    "def predict_toxicity(text, model, tokenizer, target_columns, optimal_thresholds, max_length=150):\n",
    "    \"\"\"\n",
    "    Predict whether a given text is toxic or non-toxic using a fine-tuned BERT model.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to be classified.\n",
    "        model: Fine-tuned BERT model.\n",
    "        tokenizer: Tokenizer used for the BERT model.\n",
    "        target_columns (list): List of target labels.\n",
    "        optimal_thresholds (list): Thresholds tuned for each label.\n",
    "        max_length (int): Maximum token length for BERT input.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the toxicity classification for each label.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Tokenize and preprocess the input text\n",
    "    encoded_input = tokenizer(\n",
    "        text,                     # Input text to be tokenized\n",
    "        max_length=max_length,    # Truncate or pad to this length\n",
    "        padding=\"max_length\",     # Add padding if text length is less than max_length\n",
    "        truncation=True,          # Truncate text if it exceeds max_length\n",
    "        return_tensors=\"pt\"       # Return data as PyTorch tensors\n",
    "    )\n",
    "    input_ids = encoded_input['input_ids'].to(model.device)  # Move input IDs to the model's device\n",
    "    attention_mask = encoded_input['attention_mask'].to(model.device)  # Move attention mask to the model's device\n",
    "\n",
    "    # Perform forward pass to get predictions\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)  # Get model outputs\n",
    "        logits = outputs.logits  # Extract logits\n",
    "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]  # Apply sigmoid to get probabilities\n",
    "\n",
    "    # Determine if each label is toxic based on optimal thresholds\n",
    "    prediction = {}\n",
    "    for i, label in enumerate(target_columns):  # Iterate through each label\n",
    "        is_toxic = probabilities[i] > optimal_thresholds[i]  # Compare probability with the threshold\n",
    "        prediction[label] = \"Toxic\" if is_toxic else \"Non-Toxic\"  # Assign \"Toxic\" or \"Non-Toxic\"\n",
    "\n",
    "    return prediction  # Return the predictions as a dictionary\n",
    "\n",
    "# Example Usage\n",
    "text = \"You've done a fabulous job\"\n",
    "predictions = predict_toxicity(text, model, tokenizer, target_columns, optimal_thresholds)\n",
    "print(f\"Predictions for '{text}':\")\n",
    "for label, result in predictions.items():\n",
    "    print(f\"{label}: {result}\")  # Print predictions for each label\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5127578,
     "sourceId": 8575067,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
